{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from tokenizer import Tokenizer\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"out/hf_model\").to(device)\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dataset = [json.loads(i) for i in open(\"positive_dataset.jsonl\", \"r\")]\n",
    "negative_dataset = [json.loads(i) for i in open(\"negative_dataset.jsonl\", \"r\")]\n",
    "\n",
    "dataset = positive_dataset + negative_dataset\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prop = 0.8\n",
    "train_dataset, val_dataset = dataset[:round(train_prop*len(dataset))], dataset[round(train_prop*len(dataset)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_and_labels = []\n",
    "for sample in tqdm(train_dataset):\n",
    "    text = sample[\"story\"]\n",
    "    tokens = tokenizer.encode(text, bos=True, eos=False)\n",
    "    tokens = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "    out = model(tokens, output_hidden_states=True)\n",
    "\n",
    "    data = {f\"layer_{idx}\": out.hidden_states[1][0][idx] for idx in range(len(out.hidden_states))}  # get d_embed of final token position of each layer\n",
    "    data.update({\"label\": sample[\"label\"]})\n",
    "    activations_and_labels.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 6\n",
    "positive_activations = torch.stack([i[f\"layer_{layer_idx}\"] for i in activations_and_labels if i[\"label\"] == 1])\n",
    "negative_activations = torch.stack([i[f\"layer_{layer_idx}\"] for i in activations_and_labels if i[\"label\"] == 0])\n",
    "\n",
    "avg_positive_activation = torch.mean(positive_activations, dim=0)\n",
    "avg_negative_activation = torch.mean(negative_activations, dim=0)\n",
    "\n",
    "direction = avg_positive_activation - avg_negative_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_and_label = []\n",
    "for sample in tqdm(val_dataset):\n",
    "    text = sample[\"story\"]\n",
    "    tokens = tokenizer.encode(text, bos=True, eos=False)\n",
    "    tokens = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "    out = model(tokens, output_hidden_states=True)\n",
    "\n",
    "    final_layer = out.hidden_states[1][0][6]\n",
    "    projection = torch.dot(direction, final_layer).item()\n",
    "    projection_and_label.append((projection, sample[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_and_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "projection_and_label = [(sigmoid(i[0]), i[1]) for i in projection_and_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve([i[1] for i in projection_and_label], [i[0] for i in projection_and_label])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [i[\"layer_6\"].tolist() for i in activations_and_labels]\n",
    "y = [i[\"label\"] for i in activations_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "clf = LogisticRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_and_labels = []\n",
    "for sample in tqdm(val_dataset):\n",
    "    text = sample[\"story\"]\n",
    "    tokens = tokenizer.encode(text, bos=True, eos=False)\n",
    "    tokens = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "    out = model(tokens, output_hidden_states=True)\n",
    "\n",
    "    data = {f\"layer_{idx}\": out.hidden_states[1][0][idx] for idx in range(len(out.hidden_states))}  # get d_embed of final token position of each layer\n",
    "    data.update({\"label\": sample[\"label\"]})\n",
    "    activations_and_labels.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [i[\"layer_6\"].tolist() for i in activations_and_labels]\n",
    "y = [i[\"label\"] for i in activations_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
